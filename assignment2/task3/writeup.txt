For starters I run the code form the blog up untill to the point where adding a sparsity constraint on the encoded representations. 
The first run took about a minute running on tritanium with epochs set to 50 runs. The results are to be seen below. Afterwards I played around with that number and run it again on 100 epochs the which took around five minutes on the same machine. One can't help but to notice how accurate the model is shaping the images. Finally I bumped that number towards 500 for more accurate results which took actactly 16 minutes [save machine] and used around 542MB of ram. I believe if one keeps running this for serveral hours would finally reach the same accurate results as in the orginal image. 

Adding a sparsity constraint on the encoded representations
------------------------------------------------------------
Afterwards I trained the model for 100 epochs with added regularization which reduces the likelihood for the model to overfit and can be trained longer. It took around ~4 mintues and took the same amount of RAM. The model ends with a  loss of 0.27 on both training and testing. The first-sight results were pretty bad for some unknow reason to me. I tweaked the params for serveral times, tried different settings, but unforutently could't get the right results as mentiond in the blog. 

Deep autoencoder
----------------
The next step was to not limit ourselves to asingle layer as encoder or decoder, we could instead use a stack of layers, such as:

[show code]


Convolutional autoencoder
---------------------------
Using convoluation neural networks on images makes somehow sense. In practical settings, autoencoders applied to images are always convolutional autoencoders --they simply perform much better. In the blog [1] there is an implmentation provided of an encoder which consits of Conv2d and MaxPooling2D layers (max pooling being used for spatial down-sampling), decoder will consist in a stack of Conv2D and UpSampling2D layers.
We ran the implemntation on 50 epochs and below is our results. our loss function was about loss: 0.1024 and val loss function 0.1069 which is somehow better than our previous models converges





[1] https://blog.keras.io/building-autoencoders-in-keras.html


